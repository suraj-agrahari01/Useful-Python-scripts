{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1c828b60",
   "metadata": {},
   "source": [
    "# cropping\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "315194f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file number :  21\n",
      "Converted :  1\n",
      "Converted :  2\n",
      "Converted :  3\n",
      "Converted :  4\n",
      "Converted :  5\n",
      "Converted :  6\n",
      "Converted :  7\n",
      "Converted :  8\n",
      "Converted :  9\n",
      "Converted :  10\n",
      "Converted :  11\n",
      "Converted :  12\n",
      "Converted :  13\n",
      "Converted :  14\n",
      "Converted :  15\n",
      "Converted :  16\n",
      "Converted :  17\n",
      "Converted :  18\n",
      "Converted :  19\n",
      "Converted :  20\n",
      " Input file number :  20\n",
      "output file number :  20\n",
      "Image cropping and displaying completed.\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import mediapipe as mp\n",
    "import random\n",
    "import os\n",
    "from IPython.display import display, Image\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "class mpFace:\n",
    "    import mediapipe as mp\n",
    "    import cv2\n",
    "      \n",
    "    def __init__(self,width=640,height=480):\n",
    "        self.findFace = self.mp.solutions.face_detection.FaceDetection()\n",
    "        self.faceMesh = self.mp.solutions.face_mesh.FaceMesh(False,3,True,0.5,0.5)\n",
    "        #(staticFrame,number of faces,True for extra iris landmarks,trackingParameter,findingParameter)\n",
    "        self.width = width\n",
    "        self.height = height\n",
    "        \n",
    "        \n",
    "    def faceBox(self,frame):#face bounding box\n",
    "        frameRGB = self.cv2.cvtColor(frame,self.cv2.COLOR_BGR2RGB)\n",
    "        results = self.findFace.process(frameRGB)\n",
    "        myFaces = []\n",
    "        if results.detections != None:\n",
    "            for face in results.detections:\n",
    "                bBox = face.location_data.relative_bounding_box\n",
    "                topLeft = (int(bBox.xmin*self.width),int(bBox.ymin*self.height))\n",
    "                bottomRight = (int((bBox.xmin+bBox.width)*self.width),int((bBox.ymin+bBox.height)*self.height))\n",
    "                myFaces.append((topLeft,bottomRight))\n",
    "        return myFaces  \n",
    "    \n",
    "    def faceLandmarks(self,frame):#Full Face Landmarks\n",
    "        frameRGB = self.cv2.cvtColor(frame,self.cv2.COLOR_BGR2RGB)# Converts BGR (OpenCV default) color format to RGB format required by MediaPipe.\n",
    "        results = self.faceMesh.process(frameRGB) #Processes the RGB frame using the faceMesh model to detect facial landmarks\n",
    "        myFacesLandmarks=[] #Initializes an empty list to store landmarks for each detected face.\n",
    "        myFaceLandmarks=[]  #Initializes an empty list to store landmarks for a single face.\n",
    "    \n",
    "        if results.multi_face_landmarks != None:\n",
    "            for faceLandmarks in results.multi_face_landmarks:\n",
    "                for lm in faceLandmarks.landmark:\n",
    "                    myFaceLandmarks.append((int(lm.x*self.width),int(lm.y*self.height),int(lm.z*self.width)))\n",
    "\n",
    "                myFacesLandmarks.append(myFaceLandmarks)            \n",
    "        return myFacesLandmarks\n",
    "\n",
    "    def faceLandmarksSimplified(self,frame):#essential face landmarks(left eyebrow,righteyebrow,left eye,right eye,inner lips,outer lips,face outline,left iris and right iris)\n",
    "        frameRGB = self.cv2.cvtColor(frame,self.cv2.COLOR_BGR2RGB)\n",
    "        results = self.faceMesh.process(frameRGB)\n",
    "        #sequenced indexes of required landmarks from original landmarks\n",
    "        points = [70,63,105,66,107,55,65,52,53,46,300,293,334,296,336,285,295,282,283,276,33,246,161,160,159,158,157,173,133,155,154,153,145,144,163,7,263,466,388,387,386,385,384,398,362,382,381,380,374,373,390,249,78,191,80,81,82,13,312,311,310,415,308,324,318,402,317,14,87,178,88,95,61,185,40,39,37,0,267,269,270,409,291,375,321,405,314,17,84,181,91,146,10,338,297,332,284,251,389,356,454,323,361,288,397,365,379,378,400,377,152,148,176,149,150,136,172,58,132,93,234,127,162,21,54,103,67,109,468,469,470,471,472,473,474,475,476,477,64,4,294]\n",
    "        myFaceLandmarksSimplified=[]\n",
    "        myFacesLandmarksSimplified=[]\n",
    "        myFaceLandmarksRearranged = [0]*len(points)\n",
    "        myIndex=[]\n",
    "    \n",
    "        if results.multi_face_landmarks != None:\n",
    "            for faceLandmarks in results.multi_face_landmarks:\n",
    "                for lm,indx in zip(faceLandmarks.landmark,range(len(faceLandmarks.landmark))):\n",
    "                    if indx in points:#only collect required landmarks\n",
    "                        myFaceLandmarksSimplified.append((int(lm.x*self.width),int(lm.y*self.height),int(lm.z*self.width)))\n",
    "                        myIndex.append(points.index(indx))#for rearranging the points, collect sequenced index\n",
    "                    for i,indx in zip(range(len(points)),myIndex):\n",
    "                        myFaceLandmarksRearranged[indx] = myFaceLandmarksSimplified[i]#rearranging according to sequenced index\n",
    "\n",
    "                myFacesLandmarksSimplified.append(myFaceLandmarksRearranged)          \n",
    "        return myFacesLandmarksSimplified\n",
    "    \n",
    "\n",
    "radius = 2\n",
    "#red = (0,0,255)\n",
    "green = (0,255,0)\n",
    "blue = (255,0,0)\n",
    "yellow = (0,255,255)\n",
    "\n",
    "\n",
    "# Define transparent colors\n",
    "transparent_red = (0, 0, 255, 0)    # Transparent red\n",
    "transparent_green = (0, 255, 0, 0)  # Transparent green\n",
    "\n",
    "#For connecting range of dots\n",
    "def connectPoints(indx1,indx2):\n",
    "    for i in range(indx1,indx2):\n",
    "        if i==(indx2-1):\n",
    "            cv2.line(frame,(face[i][0],face[i][1]),(face[indx1][0],face[indx1][1]),transparent_green,1)\n",
    "            break\n",
    "        cv2.line(frame,(face[i][0],face[i][1]),(face[i+1][0],face[i+1][1]),transparent_green,1)\n",
    "        \n",
    "#Finding length between two points\n",
    "def findRadius(pt1,pt2):\n",
    "    x1,y1 = (pt1[0],pt1[1])\n",
    "    x2,y2 = (pt2[0],pt2[1])\n",
    "    radius = math.sqrt(((y2-y1)*(y2-y1))+((x2-x1)*(x2-x1)))\n",
    "    return radius\n",
    "\n",
    "#boundary box code \n",
    "def findBoundingBox(lip_landmarks, margin=30):\n",
    "    min_x = min(lip_landmarks, key=lambda x: x[0])[0] - margin\n",
    "    max_x = max(lip_landmarks, key=lambda x: x[0])[0] + margin\n",
    "    min_y = min(lip_landmarks, key=lambda x: x[1])[1] - margin\n",
    "    max_y = max(lip_landmarks, key=lambda x: x[1])[1] + margin\n",
    "    return (min_x, min_y, max_x, max_y)\n",
    "\n",
    "def lips_detect(image_path):\n",
    "    # Load an image from the filesystem\n",
    "    original_frame = cv2.imread(image_path)\n",
    "\n",
    "    # Resize the image to a fixed size (640x480)\n",
    "    fixed_width = 640\n",
    "    fixed_height = 480\n",
    "    frame = cv2.resize(original_frame, (fixed_width, fixed_height))\n",
    "    \n",
    "    # Initialize the variable before the loop\n",
    "    outer_lip_cropped = None\n",
    "\n",
    "    # Perform face detection and lip landmarks\n",
    "    faceLm = mpFace()\n",
    "    faces = faceLm.faceLandmarksSimplified(frame)\n",
    "    \n",
    "    for face in faces:\n",
    "        outer_lip_landmarks = face[72:92]\n",
    "        outer_lip_box = findBoundingBox(outer_lip_landmarks, margin=10)\n",
    "\n",
    "        # Crop the outer lip region\n",
    "        outer_lip_cropped = frame[outer_lip_box[1]:outer_lip_box[3], outer_lip_box[0]:outer_lip_box[2]]\n",
    "\n",
    "    return frame, outer_lip_cropped\n",
    "\n",
    "def image_generator(folder_path, file_extensions):\n",
    "    for filename in os.listdir(folder_path):\n",
    "        if filename.lower().endswith(file_extensions):\n",
    "            yield os.path.join(folder_path, filename)\n",
    "\n",
    "def process_images(image_paths):\n",
    "    for image_path in image_paths:\n",
    "        output_frame, cropped_lips = lips_detect(image_path)  # Call lips_detect function\n",
    "        \n",
    "        if cropped_lips is not None:  # Check if lips were detected\n",
    "            # Display the cropped image using PIL\n",
    "            display(Image.fromarray(cv2.cvtColor(cropped_lips, cv2.COLOR_BGR2RGB)))\n",
    "            \n",
    "            \n",
    "import os\n",
    "import random\n",
    "import cv2\n",
    "from PIL import Image\n",
    "from IPython.display import display\n",
    "\n",
    "# Define the folder path and output folder\n",
    "folder_path = r'C:\\Users\\suraj\\Desktop\\happy sad netural\\without_padding\\train\\happy\\9'\n",
    "output_folder = r'C:\\Users\\suraj\\Desktop\\happy sad netural\\without_padding\\train\\happy\\9\\1'\n",
    "\n",
    "# Create the output folder if it doesn't exist\n",
    "if not os.path.exists(output_folder):\n",
    "    os.makedirs(output_folder)\n",
    "    \n",
    "\n",
    "lst = os.listdir(folder_path) # input directory path\n",
    "file_number = len(lst)\n",
    "\n",
    "print('file number : ',file_number)\n",
    "\n",
    "# Iterate through images, detect lips, crop, and display\n",
    "max_images = file_number  # Limit the number of images processed\n",
    "image_count = 0\n",
    "\n",
    "for filename in os.listdir(folder_path):\n",
    "    if image_count >= max_images:\n",
    "        break\n",
    "\n",
    "    if filename.lower().endswith(('.png', '.jpg', '.jpeg', '.gif', '.bmp')):\n",
    "        image_count += 1\n",
    "        image_path = os.path.join(folder_path, filename)\n",
    "        output_frame, cropped_lips = lips_detect(image_path)  # Call lips_detect function\n",
    "        \n",
    "        if cropped_lips is not None:  # Check if lips were detected\n",
    "            \n",
    "            # Save the cropped image to the output folder\n",
    "            output_filename = os.path.splitext(filename)[0] + '_cropped.jpg'\n",
    "            output_path = os.path.join(output_folder, output_filename)\n",
    "            cv2.imwrite(output_path, cropped_lips)\n",
    "            \n",
    "            # Display the cropped image using PIL\n",
    "            #display(Image.fromarray(cv2.cvtColor(cropped_lips, cv2.COLOR_BGR2RGB)))\n",
    "            print('Converted : ', image_count)\n",
    "          \n",
    "            \n",
    "            # Save the cropped image to the output folder\n",
    "            output_filename = os.path.splitext(filename)[0] + '_cropped.jpg'\n",
    "            output_path = os.path.join(output_folder, output_filename)\n",
    "            cv2.imwrite(output_path, cropped_lips)\n",
    "        \n",
    "        \n",
    "lst = os.listdir(output_folder) # output directory path\n",
    "output_file_number = len(lst)\n",
    "\n",
    "\n",
    "print(\" Input file number : \", image_count)\n",
    "print(\"output file number : \", output_file_number)\n",
    "print(\"Image cropping and displaying completed.\")\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "365225c6",
   "metadata": {},
   "source": [
    "# letter box "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3e577bf4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file number :  21\n",
      "Converted :  1\n",
      "Converted :  2\n",
      "Converted :  3\n",
      "Converted :  4\n",
      "Converted :  5\n",
      "Converted :  6\n",
      "Converted :  7\n",
      "Converted :  8\n",
      "Converted :  9\n",
      "Converted :  10\n",
      "Converted :  11\n",
      "Converted :  12\n",
      "Converted :  13\n",
      "Converted :  14\n",
      "Converted :  15\n",
      "Converted :  16\n",
      "Converted :  17\n",
      "Converted :  18\n",
      "Converted :  19\n",
      "Converted :  20\n",
      "Letterboxing and saving complete.\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "import os\n",
    "\n",
    "def letterbox_images_in_folder(input_folder, output_folder, new_width, new_height, max_images=None):\n",
    "    # Create the output folder if it doesn't exist\n",
    "    if not os.path.exists(output_folder):\n",
    "        os.makedirs(output_folder)\n",
    "\n",
    "    lst = os.listdir(input_folder)  # Input directory path\n",
    "    file_number = len(lst)\n",
    "    print('file number : ', file_number)\n",
    "\n",
    "    # Iterate through images, resize using letterbox, and save\n",
    "    image_count = 0\n",
    "\n",
    "    for filename in os.listdir(input_folder):\n",
    "        if max_images is not None and image_count >= max_images:\n",
    "            break\n",
    "\n",
    "        if filename.lower().endswith(('.png', '.jpg', '.jpeg', '.gif', '.bmp')):  # Adjust the file extension if needed\n",
    "            image_count += 1\n",
    "            # Load the original image\n",
    "            original_image = Image.open(os.path.join(input_folder, filename))\n",
    "\n",
    "            # Calculate the scaling factors for resizing\n",
    "            width_ratio = new_width / original_image.width\n",
    "            height_ratio = new_height / original_image.height\n",
    "            scaling_factor = min(width_ratio, height_ratio)\n",
    "\n",
    "            # Calculate the new dimensions after resizing\n",
    "            target_width = int(original_image.width * scaling_factor)\n",
    "            target_height = int(original_image.height * scaling_factor)\n",
    "\n",
    "            # Resize using the Letterbox technique\n",
    "            #resized_image = original_image.resize((target_width, target_height), Image.ANTIALIAS)\n",
    "            resized_image = original_image.resize((target_width, target_height), Image.Resampling.LANCZOS)\n",
    "            letterboxed_image = Image.new(\"RGB\", (new_width, new_height), (255, 215, 174))\n",
    "\n",
    "            # Calculate the position to paste the resized image\n",
    "            paste_x = (new_width - target_width) // 2\n",
    "            paste_y = (new_height - target_height) // 2\n",
    "\n",
    "            # Paste the resized image onto the letterboxed image\n",
    "            letterboxed_image.paste(resized_image, (paste_x, paste_y))\n",
    "\n",
    "            letterboxed_filename = os.path.splitext(filename)[0] + \"_letterboxed.jpg\"\n",
    "            output_path = os.path.join(output_folder, letterboxed_filename)\n",
    "            letterboxed_image.save(output_path)\n",
    "\n",
    "            print('Converted : ', image_count)\n",
    "\n",
    "    print(\"Letterboxing and saving complete.\")\n",
    "\n",
    "# Define your input and output paths, and other parameters\n",
    "input_folder = r\"C:\\Users\\suraj\\Desktop\\happy sad netural\\without_padding\\train\\happy\\9\\1\"\n",
    "output_folder = r\"C:\\Users\\suraj\\Desktop\\happy sad netural\\without_padding\\train\\happy\\9\\1\\letterboxed\"\n",
    "new_width = 224\n",
    "new_height = 224\n",
    "max_images = None  # Set the maximum number of images to process, or leave it as None to process all\n",
    "\n",
    "# Call the function to letterbox and save images\n",
    "letterbox_images_in_folder(input_folder, output_folder, new_width, new_height, max_images)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdd0566b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
